{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Flight Delay\n",
    "\n",
    "Problem Set-up:\n",
    "We define a delayed flight to be one that is delayed by >= 15 minutes. \n",
    "The prediction problem is to train a model that can classify flights, to predict if they will or will not be delayed.\n",
    "\n",
    "Use case:\n",
    "- The idea is that this model would be useful to choosing airlines, flightpaths, airports, at the time of booking, relatively in advance of the scheduled departure (days, weeks, months ahead of time). Therefore, the prediction problem will focus on features that can be known in advance, rather than predicting using day-off features like weather and previous flights from that day. \n",
    "\n",
    "Notes:\n",
    "- We restrict the analysis to relatively large airport, those with more than 20 (domestic) flights a day\n",
    "\n",
    "# Create separate models to predict for each airport \n",
    "\n",
    "Motivation:\n",
    "The weights that should eb put on features (e.g. airlines) may differ depending on the airport (see e.g. NB 4B) since different airports can have different environments (e.g. San Diego and Chicago winters are very different; American Airlines is better in Tuscon than in Anchorage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn. metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import custom code\n",
    "from flightdelay.fld import io as flio\n",
    "airlines_df, airports_df, flights_df = flio.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter data to keys of interest\n",
    "keys = ['MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'ORIGIN_AIRPORT',\n",
    "       'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME',\n",
    "       'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME',\n",
    "       'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN',\n",
    "       'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY']\n",
    "flights_df = flights_df[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove airports with less than a certain number of flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_airports, airport_inverse, airport_count = np.unique(flights_df['ORIGIN_AIRPORT'],return_counts=True,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine number of flights for the origin airport\n",
    "Nflights_orig = np.zeros(len(airport_inverse))\n",
    "for i in range(len(all_airports)):\n",
    "    Nflights_orig[np.where(airport_inverse==i)] = airport_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_df = flights_df.loc[flights_df.index[Nflights_orig>=7300]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove cancelled flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>98</td>\n",
       "      <td>N407AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>5</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1448</td>\n",
       "      <td>404.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>430</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2336</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>PBI</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2330</td>\n",
       "      <td>737.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>750</td>\n",
       "      <td>741.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>840</td>\n",
       "      <td>N171US</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CLT</td>\n",
       "      <td>20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>2296</td>\n",
       "      <td>800.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>806</td>\n",
       "      <td>811.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>258</td>\n",
       "      <td>N3HYAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2342</td>\n",
       "      <td>748.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>805</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>135</td>\n",
       "      <td>N527AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>25</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1448</td>\n",
       "      <td>254.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>320</td>\n",
       "      <td>259.0</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER ORIGIN_AIRPORT  \\\n",
       "0      1    1            4      AS             98      N407AS            ANC   \n",
       "1      1    1            4      AA           2336      N3KUAA            LAX   \n",
       "2      1    1            4      US            840      N171US            SFO   \n",
       "3      1    1            4      AA            258      N3HYAA            LAX   \n",
       "4      1    1            4      AS            135      N527AS            SEA   \n",
       "\n",
       "  DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  DEPARTURE_TIME      ...        \\\n",
       "0                 SEA                    5          2354.0      ...         \n",
       "1                 PBI                   10             2.0      ...         \n",
       "2                 CLT                   20            18.0      ...         \n",
       "3                 MIA                   20            15.0      ...         \n",
       "4                 ANC                   25            24.0      ...         \n",
       "\n",
       "   WHEELS_OFF  SCHEDULED_TIME  ELAPSED_TIME  AIR_TIME  DISTANCE  WHEELS_ON  \\\n",
       "0        15.0           205.0         194.0     169.0      1448      404.0   \n",
       "1        14.0           280.0         279.0     263.0      2330      737.0   \n",
       "2        34.0           286.0         293.0     266.0      2296      800.0   \n",
       "3        30.0           285.0         281.0     258.0      2342      748.0   \n",
       "4        35.0           235.0         215.0     199.0      1448      254.0   \n",
       "\n",
       "   TAXI_IN  SCHEDULED_ARRIVAL  ARRIVAL_TIME  ARRIVAL_DELAY  \n",
       "0      4.0                430         408.0          -22.0  \n",
       "1      4.0                750         741.0           -9.0  \n",
       "2     11.0                806         811.0            5.0  \n",
       "3      8.0                805         756.0           -9.0  \n",
       "4      5.0                320         259.0          -21.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df = flights_df.dropna()\n",
    "flights_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute features\n",
    "* one-hot day of week\n",
    "* one-hot month\n",
    "* one-hot airline\n",
    "* one-hot airport\n",
    "* one-hot departure hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Original feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_onehot_feat_dict_from_vals(df, feat_key, feat_name, feat_cutoffs):\n",
    "    \n",
    "    # Create keys\n",
    "    N_feat = len(feat_cutoffs) - 1\n",
    "    keys = [0]*N_feat\n",
    "    for i in range(N_feat):\n",
    "        keys[i] = 'f_'+feat_name+'_'+ str(feat_cutoffs[i])\n",
    "    # Find the indices for each class\n",
    "    feat_dict = {}\n",
    "    for i in range(N_feat):\n",
    "        feat_dict[keys[i]] = np.transpose(\n",
    "                    np.logical_and(df[feat_key].values>= feat_cutoffs[i],\n",
    "                                df[feat_key].values<feat_cutoffs[i+1]))\n",
    "    return feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoffs = np.arange(60,780,60)\n",
    "original_feat = make_onehot_feat_dict_from_vals(flights_df,\n",
    "                    'SCHEDULED_TIME', 'dur', cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_onehot_feat_dict(df, feat_key, feat_name):\n",
    "    # Create features for each day of the week\n",
    "    feat_vals = df[feat_key].values\n",
    "    all_vals = np.unique(feat_vals)\n",
    "    N_vals = len(all_vals)\n",
    "    N_feat = N_vals - 1\n",
    "\n",
    "    # Create keys\n",
    "    keys = [0]*N_feat\n",
    "    for i in range(N_feat):\n",
    "        keys[i] = 'f_'+feat_name+'_'+ str(all_vals[i])\n",
    "\n",
    "    # Create value for each training example in dict\n",
    "    feat_dict = {}\n",
    "    for i, k in enumerate(keys):\n",
    "        this_day = all_vals[i]\n",
    "        feat_dict[k] = feat_vals == this_day\n",
    "    return feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daysfeat_dict = make_onehot_feat_dict(flights_df, 'DAY_OF_WEEK', 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthsfeat_dict = make_onehot_feat_dict(flights_df, 'MONTH', 'month') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Departing airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dapfeat_dict = make_onehot_feat_dict(flights_df, 'ORIGIN_AIRPORT', 'dap') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfeat_dict = make_onehot_feat_dict(flights_df, 'AIRLINE', 'al') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Departure hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add departure hour as a feature\n",
    "flights_df['HOUR_DEPARTURE'] = np.floor(flights_df['SCHEDULED_DEPARTURE'].values/100).astype(int)\n",
    "hrfeat_dict = make_onehot_feat_dict(flights_df, 'HOUR_DEPARTURE', 'hr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dicts = [original_feat, daysfeat_dict, monthsfeat_dict, dapfeat_dict, alfeat_dict, hrfeat_dict]\n",
    "feat_dict = all_dicts[0].copy()\n",
    "for d in all_dicts[1:]:\n",
    "    feat_dict.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_al_AA</th>\n",
       "      <th>f_al_AS</th>\n",
       "      <th>f_al_B6</th>\n",
       "      <th>f_al_DL</th>\n",
       "      <th>f_al_EV</th>\n",
       "      <th>f_al_F9</th>\n",
       "      <th>f_al_HA</th>\n",
       "      <th>f_al_MQ</th>\n",
       "      <th>f_al_NK</th>\n",
       "      <th>f_al_OO</th>\n",
       "      <th>...</th>\n",
       "      <th>f_month_10</th>\n",
       "      <th>f_month_11</th>\n",
       "      <th>f_month_2</th>\n",
       "      <th>f_month_3</th>\n",
       "      <th>f_month_4</th>\n",
       "      <th>f_month_5</th>\n",
       "      <th>f_month_6</th>\n",
       "      <th>f_month_7</th>\n",
       "      <th>f_month_8</th>\n",
       "      <th>f_month_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  f_al_AA f_al_AS f_al_B6 f_al_DL f_al_EV f_al_F9 f_al_HA f_al_MQ f_al_NK  \\\n",
       "0   False    True   False   False   False   False   False   False   False   \n",
       "1    True   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3    True   False   False   False   False   False   False   False   False   \n",
       "4   False    True   False   False   False   False   False   False   False   \n",
       "\n",
       "  f_al_OO    ...    f_month_10 f_month_11 f_month_2 f_month_3 f_month_4  \\\n",
       "0   False    ...         False      False     False     False     False   \n",
       "1   False    ...         False      False     False     False     False   \n",
       "2   False    ...         False      False     False     False     False   \n",
       "3   False    ...         False      False     False     False     False   \n",
       "4   False    ...         False      False     False     False     False   \n",
       "\n",
       "  f_month_5 f_month_6 f_month_7 f_month_8 f_month_9  \n",
       "0     False     False     False     False     False  \n",
       "1     False     False     False     False     False  \n",
       "2     False     False     False     False     False  \n",
       "3     False     False     False     False     False  \n",
       "4     False     False     False     False     False  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame.from_dict(feat_dict)\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_flights = len(flights_df)\n",
    "N_train = int(N_flights*.7)\n",
    "N_test = N_flights - N_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_al_AA</th>\n",
       "      <th>f_al_AS</th>\n",
       "      <th>f_al_B6</th>\n",
       "      <th>f_al_DL</th>\n",
       "      <th>f_al_EV</th>\n",
       "      <th>f_al_F9</th>\n",
       "      <th>f_al_HA</th>\n",
       "      <th>f_al_MQ</th>\n",
       "      <th>f_al_NK</th>\n",
       "      <th>f_al_OO</th>\n",
       "      <th>...</th>\n",
       "      <th>f_month_10</th>\n",
       "      <th>f_month_11</th>\n",
       "      <th>f_month_2</th>\n",
       "      <th>f_month_3</th>\n",
       "      <th>f_month_4</th>\n",
       "      <th>f_month_5</th>\n",
       "      <th>f_month_6</th>\n",
       "      <th>f_month_7</th>\n",
       "      <th>f_month_8</th>\n",
       "      <th>f_month_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  f_al_AA f_al_AS f_al_B6 f_al_DL f_al_EV f_al_F9 f_al_HA f_al_MQ f_al_NK  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False    True   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False    True   False   False   False   False   \n",
       "\n",
       "  f_al_OO    ...    f_month_10 f_month_11 f_month_2 f_month_3 f_month_4  \\\n",
       "0   False    ...         False      False     False     False     False   \n",
       "1   False    ...         False      False     False     False     False   \n",
       "2   False    ...         False      False     False     False     False   \n",
       "3   False    ...         False      False     False     False     False   \n",
       "4   False    ...         False      False     False     False     False   \n",
       "\n",
       "  f_month_5 f_month_6 f_month_7 f_month_8 f_month_9  \n",
       "0     False     False     False      True     False  \n",
       "1     False     False     False     False     False  \n",
       "2     False     False     False     False     False  \n",
       "3      True     False     False     False     False  \n",
       "4     False      True     False     False     False  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle data\n",
    "np.random.seed(0)\n",
    "flight_shuff_idx = np.random.permutation(df_feat.index)\n",
    "df_shuffle = df_feat.loc[flight_shuff_idx]\n",
    "\n",
    "labels_preshuffle = flights_df['DEPARTURE_DELAY'].values\n",
    "labels_shuffle = labels_preshuffle[flight_shuff_idx]\n",
    "df_shuffle = df_shuffle.reset_index(drop=True)\n",
    "df_shuffle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delay_cutoff = 15\n",
    "\n",
    "y_train = labels_shuffle[:N_train] > delay_cutoff\n",
    "y_test = labels_shuffle[N_train:N_train+N_test] > delay_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # zscore all features\n",
    "# from scipy.stats import zscore\n",
    "# df_shuffle = df_shuffle.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = df_shuffle.loc[np.arange(N_train)]\n",
    "X_test = df_shuffle.loc[np.arange(N_train,N_train+N_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.3 s, sys: 6.53 s, total: 1min\n",
      "Wall time: 59.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run model for all individual feature sets\n",
    "\n",
    "models = LogisticRegression(C=1)\n",
    "models.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "train_aucs = roc_auc_score(y_train, models.predict_proba(X_train)[:,1])\n",
    "test_aucs = roc_auc_score(y_test, models.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671633430506\n",
      "0.671929005322\n"
     ]
    }
   ],
   "source": [
    "print(train_aucs)\n",
    "print(test_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.53813559322\n",
      "Recall:  0.000447474587319\n",
      "[[1290934     109]\n",
      " [ 283688     127]]\n",
      "0.819795181534\n",
      "0.819783751932\n",
      "Sensitivity:  0.999915572138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "all_confuse = confusion_matrix(y_test, models.predict(X_test))\n",
    "print('Precision: ', all_confuse[1,1]/(all_confuse[1,1]+all_confuse[0,1]))\n",
    "print('Recall: ', all_confuse[1,1]/(all_confuse[1,1]+all_confuse[1,0]))\n",
    "\n",
    "print(all_confuse)\n",
    "print((all_confuse[0,0]+all_confuse[1,1])/np.sum(all_confuse))\n",
    "print((all_confuse[0,0]+all_confuse[0,1])/np.sum(all_confuse))\n",
    "print('Sensitivity: ', all_confuse[0,0]/(all_confuse[0,0]+all_confuse[0,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_al_NK\n",
      "0.324596033373\n",
      "f_al_AS\n",
      "-0.838896002258\n"
     ]
    }
   ],
   "source": [
    "als_idx = np.arange(0,13)\n",
    "all_als = np.array(list(X_train.keys()))[als_idx]\n",
    "\n",
    "al_max_idx = np.argmax(models.coef_[0][als_idx])\n",
    "print(X_train.keys()[al_max_idx])\n",
    "print(models.coef_[0][al_max_idx])\n",
    "\n",
    "al_min_idx = np.argmin(models.coef_[0][als_idx])\n",
    "print(X_train.keys()[al_min_idx])\n",
    "print(models.coef_[0][al_min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_dap_BTR\n",
      "0.168258355915\n",
      "f_dap_LIH\n",
      "-0.797502799085\n"
     ]
    }
   ],
   "source": [
    "als_idx = np.arange(13,110)\n",
    "all_als = np.array(list(X_train.keys()))[als_idx]\n",
    "\n",
    "al_max_idx = np.argmax(models.coef_[0][als_idx]) + 13\n",
    "print(X_train.keys()[al_max_idx])\n",
    "print(models.coef_[0][al_max_idx])\n",
    "\n",
    "al_min_idx = np.argmin(models.coef_[0][als_idx]) + 13\n",
    "print(X_train.keys()[al_min_idx])\n",
    "print(models.coef_[0][al_min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_day_1' 'f_day_2' 'f_day_3' 'f_day_4' 'f_day_5' 'f_day_6']\n",
      "f_day_1\n",
      "0.105992697892\n",
      "f_day_6\n",
      "-0.101191776475\n"
     ]
    }
   ],
   "source": [
    "als_idx = np.arange(110,116)\n",
    "all_als = np.array(list(X_train.keys()))[als_idx]\n",
    "print(all_als)\n",
    "al_max_idx = np.argmax(models.coef_[0][als_idx]) + 110\n",
    "print(X_train.keys()[al_max_idx])\n",
    "print(models.coef_[0][al_max_idx])\n",
    "\n",
    "al_min_idx = np.argmin(models.coef_[0][als_idx]) + 110\n",
    "print(X_train.keys()[al_min_idx])\n",
    "print(models.coef_[0][al_min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_dur_120' 'f_dur_180' 'f_dur_240' 'f_dur_300' 'f_dur_360' 'f_dur_420'\n",
      " 'f_dur_480' 'f_dur_540' 'f_dur_60' 'f_dur_600' 'f_dur_660']\n",
      "f_dur_480\n",
      "0.931193278409\n",
      "f_dur_60\n",
      "0.0895921811875\n"
     ]
    }
   ],
   "source": [
    "als_idx = np.arange(116,127)\n",
    "all_als = np.array(list(X_train.keys()))[als_idx]\n",
    "print(all_als)\n",
    "al_max_idx = np.argmax(models.coef_[0][als_idx]) + 116\n",
    "print(X_train.keys()[al_max_idx])\n",
    "print(models.coef_[0][al_max_idx])\n",
    "\n",
    "al_min_idx = np.argmin(models.coef_[0][als_idx]) + 116\n",
    "print(X_train.keys()[al_min_idx])\n",
    "print(models.coef_[0][al_min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_hr_0' 'f_hr_1' 'f_hr_10' 'f_hr_11' 'f_hr_12' 'f_hr_13' 'f_hr_14'\n",
      " 'f_hr_15' 'f_hr_16' 'f_hr_17' 'f_hr_18' 'f_hr_19' 'f_hr_2' 'f_hr_20'\n",
      " 'f_hr_21' 'f_hr_22' 'f_hr_3' 'f_hr_4' 'f_hr_5' 'f_hr_6' 'f_hr_7' 'f_hr_8'\n",
      " 'f_hr_9']\n",
      "f_hr_3\n",
      "0.602734617711\n",
      "f_hr_5\n",
      "-1.4564623433\n"
     ]
    }
   ],
   "source": [
    "als_idx = np.arange(127,150)\n",
    "all_als = np.array(list(X_train.keys()))[als_idx]\n",
    "print(all_als)\n",
    "al_max_idx = np.argmax(models.coef_[0][als_idx]) + 127\n",
    "print(X_train.keys()[al_max_idx])\n",
    "print(models.coef_[0][al_max_idx])\n",
    "\n",
    "al_min_idx = np.argmin(models.coef_[0][als_idx]) + 127\n",
    "print(X_train.keys()[al_min_idx])\n",
    "print(models.coef_[0][al_min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_month_1' 'f_month_10' 'f_month_11' 'f_month_2' 'f_month_3' 'f_month_4'\n",
      " 'f_month_5' 'f_month_6' 'f_month_7' 'f_month_8' 'f_month_9']\n",
      "f_month_6\n",
      "0.197257662881\n",
      "f_month_10\n",
      "-0.640531211346\n"
     ]
    }
   ],
   "source": [
    "als_idx = np.arange(150,161)\n",
    "all_als = np.array(list(X_train.keys()))[als_idx]\n",
    "print(all_als)\n",
    "al_max_idx = np.argmax(models.coef_[0][als_idx]) + 150\n",
    "print(X_train.keys()[al_max_idx])\n",
    "print(models.coef_[0][al_max_idx])\n",
    "\n",
    "al_min_idx = np.argmin(models.coef_[0][als_idx]) + 150\n",
    "print(X_train.keys()[al_min_idx])\n",
    "print(models.coef_[0][al_min_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train models with individual onehot feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_sets = [0]*len(all_dicts)\n",
    "for i in range(len(all_dicts)):\n",
    "    feat_sets[i] = list(all_dicts[i].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Run model for all individual feature sets\n",
    "models = np.zeros(len(feat_sets),dtype=object)\n",
    "train_aucs = np.zeros(len(feat_sets))\n",
    "test_aucs = np.zeros(len(feat_sets))\n",
    "test_confuse = np.zeros(len(feat_sets),dtype=list)\n",
    "for i, ks in enumerate(feat_sets):\n",
    "    print(i)\n",
    "    # Train model\n",
    "    models[i] = LogisticRegression(C=1)\n",
    "    models[i].fit(X_train[ks], y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_aucs[i] = roc_auc_score(y_train, models[i].predict_proba(X_train[ks])[:,1])\n",
    "    test_aucs[i] = roc_auc_score(y_test, models[i].predict_proba(X_test[ks])[:,1])\n",
    "    \n",
    "    test_confuse[i] = confusion_matrix(y_test, models[i].predict(X_test[ks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_dur_60\n",
      "f_day_1\n",
      "f_month_1\n",
      "f_dap_ABQ\n",
      "f_al_AA\n",
      "f_hr_0\n"
     ]
    }
   ],
   "source": [
    "print(feat_sets[0][0])\n",
    "print(feat_sets[1][0])\n",
    "print(feat_sets[2][0])\n",
    "print(feat_sets[3][0])\n",
    "print(feat_sets[4][0])\n",
    "print(feat_sets[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51792379  0.5177713   0.56500726  0.56018308  0.56829332  0.6284955 ]\n",
      "[ 0.51777684  0.51760399  0.56546363  0.55982328  0.56793727  0.62854951]\n"
     ]
    }
   ],
   "source": [
    "print(train_aucs)\n",
    "print(test_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_dur_60\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_day_1\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_month_1\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_dap_ABQ\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_al_AA\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_hr_0\n",
      "Precision:  nan\n",
      "Recall:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for i, ks in enumerate(feat_sets):\n",
    "    print(ks[0])\n",
    "    print(test_confuse)\n",
    "    print('Precision: ', test_confuse[i][1,1]/(test_confuse[i][1,1]+test_confuse[i][0,1]))\n",
    "    print('Recall: ', test_confuse[i][1,1]/(test_confuse[i][1,1]+test_confuse[i][1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train models with removing 1 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_sets = np.zeros(len(all_dicts),dtype=list)\n",
    "for i in range(len(all_dicts)):\n",
    "    feat_sets[i] = list(all_dicts[i].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Run model for all individual feature sets\n",
    "models = np.zeros(len(feat_sets),dtype=object)\n",
    "train_aucs = np.zeros(len(feat_sets))\n",
    "test_aucs = np.zeros(len(feat_sets))\n",
    "for i, ks in enumerate(feat_sets):\n",
    "    print(i)\n",
    "    # Choose feats\n",
    "    fis = np.delete(np.arange(len(feat_sets)),i)\n",
    "    ks2 = np.hstack(feat_sets[fis])\n",
    "\n",
    "    # Train model\n",
    "    models[i] = LogisticRegression(C=1)\n",
    "    models[i].fit(X_train[ks2], y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_aucs[i] = roc_auc_score(y_train, models[i].predict_proba(X_train[ks2])[:,1])\n",
    "    test_aucs[i] = roc_auc_score(y_test, models[i].predict_proba(X_test[ks2])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6708183   0.67062881  0.6581474   0.66732485  0.66153361  0.61135848]\n",
      "[ 0.67108736  0.67097393  0.65820497  0.66757322  0.6619307   0.61134654]\n"
     ]
    }
   ],
   "source": [
    "print(train_aucs)\n",
    "print(test_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_dur_60\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_day_1\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_month_1\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_dap_ABQ\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_al_AA\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "f_hr_0\n",
      "Precision:  nan\n",
      "Recall:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for i, ks in enumerate(feat_sets):\n",
    "    print(ks[0])\n",
    "    print(test_confuse)\n",
    "    print('Precision: ', test_confuse[i][1,1]/(test_confuse[i][1,1]+test_confuse[i][0,1]))\n",
    "    print('Recall: ', test_confuse[i][1,1]/(test_confuse[i][1,1]+test_confuse[i][1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
