{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words, words, words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import custom code\n",
    "import fld.io as flio\n",
    "import fld.preds as flp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set data path\n",
    "dat_path = \"/Users/thomasdonoghue/Documents/UCSD/1-Classes/2016-2017/\" \\\n",
    "           \"2-Winter/CSE255_WebMining/Assignments/Assgn-2/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set labels\n",
    "def create_label(row):\n",
    "    if row['DEPARTURE_DELAY'] > 15: return 1\n",
    "    else: return 0\n",
    "    \n",
    "def labels(df):\n",
    "    return np.array(df['LABEL'])#.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features_b(df):\n",
    "    return np.array(flights_df[['DISTANCE','DAY_OF_WEEK']].values)\n",
    " \n",
    "def features(df):\n",
    "    \n",
    "    h = np.array([1 if airline_hub[dat[1]] == dat[0] else 0 for dat in df[['ORIGIN_AIRPORT', 'AIRLINE']].values]).reshape(-1, 1)\n",
    "    \n",
    "    hn = np.array([airline_hubness[line] for line in df.AIRLINE.values]).reshape(-1, 1)  \n",
    "    \n",
    "    ce = np.array([airport_cen[port] for port in df.ORIGIN_AIRPORT.values]).reshape(-1, 1)\n",
    "    cc = np.array([airport_clo_cen[port] for port in df.ORIGIN_AIRPORT.values]).reshape(-1, 1)\n",
    "    de = np.array([airport_deg[port] for port in df.ORIGIN_AIRPORT.values]).reshape(-1, 1)\n",
    "    nd = np.array([airport_ne_deg[port] for port in df.ORIGIN_AIRPORT.values]).reshape(-1, 1)\n",
    "        \n",
    "    oh_hour = flp.make_onehot_feat_mat(df, 'HOUR')\n",
    "    \n",
    "    oh_month = flp.make_onehot_feat_mat(df, 'MONTH')\n",
    "    #oh_day = flp.make_onehot_feat_mat(df, 'DAY_OF_WEEK')\n",
    "    \n",
    "    oh_line = flp.make_onehot_feat_mat(df, 'AIRLINE')\n",
    "    oh_o_port = flp.make_onehot_feat_mat(df, 'ORIGIN_AIRPORT')\n",
    "    #oh_d_port = flp.make_onehot_feat_mat(df, 'DESTINATION_AIRPORT')\n",
    "    \n",
    "    lat_lon_dep = np.array(df[['LAT_DEP', 'LON_DEP']].values)\n",
    "    #lat_lon_arr = np.array(df[['LAT_ARR', 'LON_ARR']].values)\n",
    "    \n",
    "    other = np.array(df[['DISTANCE']].values)\n",
    "\n",
    "    #return np.hstack([oh_line, oh_o_port, oh_month, other])\n",
    "    return np.hstack([oh_line, oh_o_port, oh_month, oh_hour, lat_lon_dep, other, h, hn, ce, cc, de, nd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%memit\n",
    "# Load data\n",
    "airlines_df, airports_df, flights_df = flio.load_data(dat_path)#, N_flights=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update airlines & airports to use new updated ones\n",
    "airlines_df = pd.read_json('new_airlines.json')\n",
    "airports_df = pd.read_json('new_airports.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make dictionary look ups for airport and airline data to use as features. \n",
    "\n",
    "# Airlines data\n",
    "airline_hub = airlines_df[['IATA_CODE', 'HUB']].set_index('IATA_CODE').to_dict()['HUB']\n",
    "airline_hubness =  airlines_df[['IATA_CODE', 'HUBNESS']].set_index('IATA_CODE').to_dict()['HUBNESS']\n",
    "\n",
    "# Airports data\n",
    "airport_cen = airports_df[['IATA_CODE', 'CEN']].set_index('IATA_CODE').to_dict()['CEN']\n",
    "airport_clo_cen = airports_df[['IATA_CODE', 'CLO_CEN']].set_index('IATA_CODE').to_dict()['CLO_CEN']\n",
    "airport_deg = airports_df[['IATA_CODE', 'DEG']].set_index('IATA_CODE').to_dict()['DEG']\n",
    "airport_ne_deg = airports_df[['IATA_CODE', 'NE_DEG']].set_index('IATA_CODE').to_dict()['NE_DEG']\n",
    "\n",
    "#airline_hub = pd.Series(airlines_df.IATA_CODE.values, index=airlines_df.HUB).to_dict()\n",
    "#airline_hub = dict((v,k) for k,v in airline_hub.items())\n",
    "#airline_hub['UA'] = 'ORD'\n",
    "#airline_hub['F9'] = 'DEN'\n",
    "#airline_hubness = pd.Series(airlines_df.IATA_CODE.values, index=airlines_df.HUBNESS).to_dict()\n",
    "#airline_hubness = dict((v,k) for k,v in airline_hubness.items())\n",
    "\n",
    "# Airports data\n",
    "#airport_cen = pd.Series(airports_df.IATA_CODE.values, index=airports_df.CEN)#.to_dict()\n",
    "#airport_cen = dict((v,k) for k,v in airport_cen.items())\n",
    "#airport_clo_cen = pd.Series(airports_df.IATA_CODE.values, index=airports_df.CLO_CEN).to_dict()\n",
    "#airport_clo_cen = dict((v,k) for k,v in airport_clo_cen.items())\n",
    "#airport_deg = pd.Series(airports_df.IATA_CODE.values, index=airports_df.DEG).to_dict()\n",
    "#airport_deg = dict((v,k) for k,v in airport_deg.items())\n",
    "#airport_ne_deg = pd.Series(airports_df.IATA_CODE.values, index=airports_df.NE_DEG).to_dict()\n",
    "#airport_ne_deg = dict((v,k) for k,v in airport_ne_deg.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop cancelled flights\n",
    "flights_df = flio.drop_cancelled(flights_df)\n",
    "\n",
    "#flights_df = flights_df[flights_df['CANCELLED'] != 1]\n",
    "#flights_df = flights_df[np.isfinite(flights_df['DEPARTURE_DELAY'])]\n",
    "#flights_df.dropna('DEPARTURE_DELAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter data to keys of interest\n",
    "keys = ['MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'ORIGIN_AIRPORT',\n",
    "       'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME',\n",
    "       'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME',\n",
    "       'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN',\n",
    "       'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY']\n",
    "flights_df = flights_df[keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove any flights with missing data\n",
    "flights_df = flights_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select busy airports\n",
    "flights_df = flio.select_busy_airports(flights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add departure hour as a feature\n",
    "flights_df['HOUR'] = np.floor(flights_df['SCHEDULED_DEPARTURE'].values/100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check which airports remain in database and select those in airport DataFrame\n",
    "used_airports = set(flights_df.ORIGIN_AIRPORT.values)\n",
    "airports_df = airports_df[airports_df.apply(lambda row: row['IATA_CODE'] in used_airports, axis=1)]\n",
    "\n",
    "# Extract all aiports present in the data\n",
    "airports = set(airports_df['IATA_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lat_lon(df):\n",
    "    \"\"\"Input: Airports DF.\"\"\"\n",
    "    \n",
    "    airports = set(df['IATA_CODE'])\n",
    "    \n",
    "    lats = dict(); lons = dict();\n",
    "    \n",
    "    for p in airports:\n",
    "        lats[p] = df.loc[df['IATA_CODE'] == p]['LATITUDE'].values[0]\n",
    "        lons[p] = df.loc[df['IATA_CODE'] == p]['LONGITUDE'].values[0]\n",
    "\n",
    "    return lats, lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Lat & Lon features to dataframe\n",
    "lats, lons = lat_lon(airports_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Center' of the USA, Lebanon, Kansas\n",
    "cen_lat = 39.810213\n",
    "cen_lon = -98.557317\n",
    "\n",
    "#\n",
    "#lats_cen = {key: lats[key] - cen_lat for key in lats.keys()}\n",
    "#lons_cen = {key: lons[key] - cen_lon for key in lons.keys()}\n",
    "\n",
    "# \n",
    "lats_cen = {key: abs(lats[key] - cen_lat) for key in lats.keys()}\n",
    "lons_cen = {key: abs(lons[key] - cen_lon) for key in lons.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ?\n",
    "lat_sc = preprocessing.MinMaxScaler((-1, 1))\n",
    "lat_dat = np.array(list(lats_cen.values()))\n",
    "lat_sc.fit(lat_dat)\n",
    "\n",
    "lon_sc = preprocessing.MinMaxScaler((-1, 1))\n",
    "lon_dat = np.array(list(lons_cen.values()))\n",
    "lon_sc.fit(lon_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ?\n",
    "lats_cen_sc = {key: lat_sc.transform(np.array(lats_cen[key]).reshape(-1, 1))[0][0] for key in lats.keys()}\n",
    "lons_cen_sc = {key: lon_sc.transform(np.array(lons_cen[key]).reshape(-1, 1))[0][0] for key in lons.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set departure airport lat & lon into flights df\n",
    "flights_df['LAT_DEP'] = flights_df['ORIGIN_AIRPORT'].map(lats_cen)\n",
    "flights_df['LON_DEP'] = flights_df['ORIGIN_AIRPORT'].map(lons_cen)\n",
    "\n",
    "# Set arrival airport lat & lon into flights df\n",
    "flights_df['LAT_ARR'] = flights_df['DESTINATION_AIRPORT'].map(lats_cen)\n",
    "flights_df['LON_ARR'] = flights_df['DESTINATION_AIRPORT'].map(lons_cen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train & test sets\n",
    "n_flights = len(flights_df)\n",
    "n_per_set = int(n_flights/2)\n",
    "np.random.seed(0)\n",
    "inds = np.random.permutation(flights_df.index)\n",
    "\n",
    "# Split\n",
    "flights_train_df = flights_df.loc[inds[:n_per_set]]\n",
    "flights_test_df = flights_df.loc[inds[n_per_set:]]\n",
    "del flights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create features representations\n",
    "X_train = features(flights_train_df)\n",
    "X_test = features(flights_test_df)\n",
    "\n",
    "# Get labels for the train set\n",
    "del_vals_train = flights_train_df['DEPARTURE_DELAY'].values\n",
    "y_train = (del_vals_train > 15).astype(int)\n",
    "\n",
    "# Get labels for the test set\n",
    "del_vals_test = flights_test_df['DEPARTURE_DELAY'].values\n",
    "y_test = (del_vals_test > 15).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intialize and train the model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59319121495891203"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model performance on train data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59289706102013351"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model performance on test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check Confusion Matrix\n",
    "preds = model.predict(X_test)\n",
    "c_mat = confusion_matrix(y_test, preds)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO BEAT: Check model performance on test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
